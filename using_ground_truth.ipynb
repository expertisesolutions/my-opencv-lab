{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "respiratory-johnston",
   "metadata": {},
   "source": [
    "# Detectors classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "musical-bargain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T12:53:23.261738Z",
     "start_time": "2021-03-24T12:53:23.182679Z"
    },
    "code_folding": [
     13,
     46
    ]
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class haar_detector():\n",
    "    def __init__(self):\n",
    "        self.detector = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_fullbody.xml'\n",
    "        #     cv2.data.haarcascades + 'haarcascade_upperbody.xml'\n",
    "        )\n",
    "\n",
    "    def process(self, frame):\n",
    "        bodies = self.detector.detectMultiScale(frame, 1.1, 1)\n",
    "        return bodies\n",
    "    \n",
    "class background_subtraction_detector():\n",
    "    def __init__(self):\n",
    "        self.detector = cv2.createBackgroundSubtractorMOG2(\n",
    "            history=150,\n",
    "            varThreshold=50\n",
    "        )\n",
    "\n",
    "    def process(self, frame):\n",
    "        # Filter image to get people blobs\n",
    "        mask = self.detector.apply(frame)\n",
    "\n",
    "        mask[mask>125] = 255\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1, 7))\n",
    "        mask = cv2.erode(mask, kernel, iterations=1)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "        mask = cv2.dilate(mask, kernel, iterations=2)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=5)   \n",
    "\n",
    "        # Consider each blob a person\n",
    "        contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bodies = []\n",
    "        for countour in contours:\n",
    "            # Calculate area and remove small elements\n",
    "            area = cv2.contourArea(countour)\n",
    "            if area > 100:\n",
    "                x, y, w, h = cv2.boundingRect(countour)\n",
    "                bodies += [(x, y, w, h)]\n",
    "\n",
    "        # Reconstruct the colors\n",
    "#         frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "        return bodies\n",
    "\n",
    "class yolo_detector():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Define YOLO files to load\n",
    "        # weights_file, cfg_file, names_file = \"pretrained_yolo/v3/yolov3-tiny.weights\", \"pretrained_yolo/v3/yolov3-tiny.cfg\", \"pretrained_yolo/v3/coco.names\"\n",
    "        weights_file, cfg_file, names_file = \"pretrained_yolo/v4/yolov4-tiny.weights\", \"pretrained_yolo/v4/yolov4-tiny.cfg\", \"pretrained_yolo/v4/coco.names\"\n",
    "\n",
    "        # YOLO and DNN Configs\n",
    "        # ref: https://docs.opencv.org/4.5.1/d6/d0f/group__dnn.html\n",
    "        self.mean = (0, 0, 0)  # YOLO doesn't use subtraction.\n",
    "        self.scale_factor = 1 / (255)  # the colorspace is normalized to match values from 0 to 1, so for 8 bits depth it should be 1/255.\n",
    "        self.blob_size = tuple([128*2]*2)  # this will impacat on precision over FPS. Smaller means faster. 320x320 is a common value.\n",
    "        self.confidence_threshold = 0.3  # 0 means no threshold. 0.5 is a common value.\n",
    "        self.supression_threshold = 0.4  # 1 means no supression. 0.4 is a common value.\n",
    "\n",
    "        dnn_target, dnn_backend = cv2.dnn.DNN_TARGET_CPU, cv2.dnn.DNN_BACKEND_DEFAULT\n",
    "        # dnn_target, dnn_backend = cv2.dnn.DNN_TARGET_CPU, cv2.dnn.DNN_BACKEND_OPENCV\n",
    "        # dnn_target, dnn_backend = cv2.dnn.DNN_TARGET_OPENCL, cv2.dnn.DNN_BACKEND_DEFAULT\n",
    "        # dnn_target, dnn_backend = cv2.dnn.DNN_TARGET_OPENCL, cv2.dnn.DNN_BACKEND_OPENCV\n",
    "        # dnn_target, dnn_backend = cv2.dnn.DNN_TARGET_CUDA, cv2.dnn.DNN_BACKEND_CUDA\n",
    "        # dnn_target, dnn_backend = cv2.dnn.DNN_TARGET_VULKAN, cv2.dnn.DNN_BACKEND_VKCOM\n",
    "\n",
    "        # Load YOLO\n",
    "        net = cv2.dnn.readNet(weights_file, cfg_file)\n",
    "        net.setPreferableBackend(dnn_backend)\n",
    "        net.setPreferableTarget(dnn_target)\n",
    "\n",
    "        classes = []\n",
    "        with open(names_file, \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "            print(f\"{len(self.classes)} classes loaded:\", end=' ')\n",
    "            print(classes)\n",
    "        layer_names = net.getLayerNames()\n",
    "        # output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        self.output_layers = net.getUnconnectedOutLayersNames()\n",
    "        self.colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "        \n",
    "        self.classes = classes\n",
    "        self.net = net\n",
    "\n",
    "    def process(self, frame):\n",
    "        # Detecting objects\n",
    "        blob = cv2.dnn.blobFromImage(frame,\n",
    "            scalefactor=self.scale_factor,\n",
    "            size=self.blob_size,\n",
    "            mean=self.mean,\n",
    "            swapRB=True,\n",
    "            crop=False,\n",
    "    #         ddepth=cv2.CV_32F\n",
    "        )\n",
    "        self.net.setInput(blob)\n",
    "        output_blobs = self.net.forward(self.output_layers)\n",
    "\n",
    "        # Extract bounding boxes for any object detected\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        for output_blob in output_blobs:\n",
    "            for detection in output_blob:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > self.confidence_threshold:\n",
    "                    center_x, center_y, w, h = detection[:4] * np.array(\n",
    "                        [frame_width, frame_height, frame_width, frame_height])\n",
    "                    x = center_x - (w / 2)\n",
    "                    y = center_y - (h / 2)\n",
    "                    boxes.append([int(x), int(y), int(w), int(h)])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # Remove coincidental detections\n",
    "        indices = cv2.dnn.NMSBoxes(\n",
    "            bboxes=boxes, \n",
    "            scores=confidences, \n",
    "            score_threshold=self.confidence_threshold, \n",
    "            nms_threshold=self.supression_threshold\n",
    "        )\n",
    "        \n",
    "        bodies = []\n",
    "        # Showing informations on the screen\n",
    "#         font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        for i in range(len(boxes)):\n",
    "            if i in indices:\n",
    "                bodies += [boxes[i]]\n",
    "#                 x, y, w, h = boxes[i]\n",
    "#                 label = classes[class_ids[i]]\n",
    "#                 confidence = round(confidences[i]*100)\n",
    "#                 color = colors[class_ids[i]]\n",
    "#                 cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "#                 cv2.putText(\n",
    "#                     frame,\n",
    "#                     text=f\"{label} : {confidence}%\",\n",
    "#                     org=(x, y-5),\n",
    "#                     fontFace=font,\n",
    "#                     fontScale=0.3,\n",
    "#                     color=color,\n",
    "#                     thickness=1\n",
    "#                 )\n",
    "\n",
    "        return bodies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-migration",
   "metadata": {},
   "source": [
    "## Getting our ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sorted-jonathan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T12:53:23.504335Z",
     "start_time": "2021-03-24T12:53:23.262598Z"
    },
    "code_folding": [
     3,
     7,
     22,
     37
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Left</th>\n",
       "      <th>Bottom</th>\n",
       "      <th>Right</th>\n",
       "      <th>Top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>-59</td>\n",
       "      <td>141</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <td>146</td>\n",
       "      <td>-48</td>\n",
       "      <td>198</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <td>209</td>\n",
       "      <td>69</td>\n",
       "      <td>269</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "      <td>-61</td>\n",
       "      <td>143</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>-49</td>\n",
       "      <td>200</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47724</th>\n",
       "      <th>3087</th>\n",
       "      <th>151</th>\n",
       "      <td>40</td>\n",
       "      <td>-110</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47731</th>\n",
       "      <th>3088</th>\n",
       "      <th>150</th>\n",
       "      <td>310</td>\n",
       "      <td>-82</td>\n",
       "      <td>356</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47732</th>\n",
       "      <th>3088</th>\n",
       "      <th>151</th>\n",
       "      <td>41</td>\n",
       "      <td>-112</td>\n",
       "      <td>88</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47739</th>\n",
       "      <th>3089</th>\n",
       "      <th>150</th>\n",
       "      <td>309</td>\n",
       "      <td>-81</td>\n",
       "      <td>355</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47740</th>\n",
       "      <th>3089</th>\n",
       "      <th>151</th>\n",
       "      <td>43</td>\n",
       "      <td>-113</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10248 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Left  Bottom  Right  Top\n",
       "Index Frame Id                           \n",
       "3     0     3      90     -59    141   81\n",
       "4     0     4     146     -48    198   95\n",
       "5     0     5     209      69    269  246\n",
       "17    1     3      92     -61    143   78\n",
       "18    1     4     149     -49    200   94\n",
       "...               ...     ...    ...  ...\n",
       "47724 3087  151    40    -110     86   14\n",
       "47731 3088  150   310     -82    356   52\n",
       "47732 3088  151    41    -112     88   13\n",
       "47739 3089  150   309     -81    355   54\n",
       "47740 3089  151    43    -113     90   11\n",
       "\n",
       "[10248 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def setup_ground_truth(ground_truth_filename, crop_window=None,resize='1080p'):\n",
    "    df = pd.read_csv(\n",
    "        ground_truth_filename,\n",
    "        header=None,\n",
    "        names=['Id', 'Frame', 'Head Valid', 'Body Valid',\n",
    "               'Head Left', 'Head Top', 'Head Right', 'Head Bottom',\n",
    "               'Body Left', 'Body Top', 'Body Right', 'Body Bottom'],\n",
    "    )\n",
    "    df['Index'] = df.index\n",
    "    df.set_index(['Index', 'Frame', 'Id'], inplace=True)\n",
    "    \n",
    "    # Selecting only the Full Body\n",
    "    df.drop(columns=[\n",
    "        'Head Valid',\n",
    "        'Head Left',\n",
    "        'Head Top',\n",
    "        'Head Right',\n",
    "        'Head Bottom'\n",
    "    ], inplace=True)\n",
    "    df.rename(columns={\n",
    "        'Body Valid': 'Valid',\n",
    "        'Body Left': 'Left',\n",
    "        'Body Top': 'Bottom',  # top-bottom reverse\n",
    "        'Body Right': 'Right',\n",
    "        'Body Bottom': 'Top'   # top-bottom reverse\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Drop all non-valid rows\n",
    "    df = df[df['Valid'] == 1]\n",
    "    df.drop(columns=['Valid'], inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Crop\n",
    "    width, height = 1920, 1080\n",
    "    if crop_window != None:\n",
    "        if len(crop_window) != 4:\n",
    "            print(\"Wrong format! Expected a tuple like \\'crop_window = (left, bottom, right, top)\\'.\")\n",
    "            raise\n",
    "        left, bottom, right, top = crop_window  \n",
    "        width, height = right - left, top - bottom\n",
    "        \n",
    "        # Drop if completely outide of the window\n",
    "        df = df[~(\n",
    "            (df['Right'] < left) |\n",
    "            (df['Bottom'] > top) |\n",
    "            (df['Left'] > right) |\n",
    "            (df['Top'] < bottom)\n",
    "        )]\n",
    "        \n",
    "        # Offset\n",
    "        df['Left'] -= left\n",
    "        df['Top'] -= bottom\n",
    "        df['Right'] -= left\n",
    "        df['Bottom'] -= bottom\n",
    "\n",
    "    # Resize\n",
    "    if resize == '1080p':\n",
    "        k_width, k_height = 1080 / width, 1920 / height\n",
    "    elif resize == '720p':\n",
    "        k_width, k_height = 1280 / width, 720 / height\n",
    "    elif resize == '480p':\n",
    "        k_width, k_height = 854 / width, 480 / height\n",
    "    elif resize == '360p':\n",
    "        k_width, k_height = 640 / width, 360 / height\n",
    "    \n",
    "    df['Left'] *= k_width\n",
    "    df['Right'] *= k_width\n",
    "    df['Top'] *= k_height\n",
    "    df['Bottom'] *= k_height\n",
    "    \n",
    "    return df.astype(int)\n",
    "\n",
    "width, height = 845, 480\n",
    "left, bottom = 600, 300\n",
    "right, top = left + width, bottom + height\n",
    "df_gt = setup_ground_truth('TownCentre-groundtruth.top', crop_window=(left, bottom, right, top), resize='360p')\n",
    "display(df_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-serve",
   "metadata": {},
   "source": [
    "# Functions to process the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "twenty-discretion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T12:53:23.515751Z",
     "start_time": "2021-03-24T12:53:23.505439Z"
    },
    "code_folding": [
     7,
     22,
     35,
     49,
     61,
     79
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "green = (0, 255, 0)\n",
    "red = (0, 0 ,255)\n",
    "\n",
    "def setup_input(input_filename):\n",
    "    vcap = cv2.VideoCapture(input_filename)\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_width = int(vcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(vcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = vcap.get(cv2.CAP_PROP_FPS)\n",
    "    n_frames = int(vcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(\"Frame width:\", frame_width)\n",
    "    print(\"Frame width:\", frame_height)\n",
    "    print(\"Video fps:\", fps)\n",
    "\n",
    "    return vcap, frame_width, frame_height, fps, n_frames\n",
    "\n",
    "def setup_output(output_filename, frame_width, frame_height, fps):\n",
    "    apiPreference = cv2.CAP_FFMPEG\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    vout = cv2.VideoWriter(\n",
    "        filename=output_filename,\n",
    "        apiPreference=apiPreference,\n",
    "        fourcc=fourcc,\n",
    "        fps=fps,\n",
    "        frameSize=(frame_width, frame_height),\n",
    "        params=[]\n",
    "    )\n",
    "    return vout\n",
    "\n",
    "def process_frames(vcap, vout, df_gt, detector, frames_to_process=100):\n",
    "    # Start app\n",
    "    window_name = \"People Detecting\"\n",
    "    cv2.startWindowThread()\n",
    "    cv2.namedWindow(window_name)\n",
    "\n",
    "    # Loop each frame\n",
    "    frame_count = 0\n",
    "    processed_frames = np.zeros(frames_to_process, dtype=object)\n",
    "    output_data = [] #Index, Frame, Id, Left, Bottom, Right, Top\n",
    "     \n",
    "    # start timer\n",
    "    start = time.time()\n",
    "    fps_timer = [0, cv2.getTickCount()]\n",
    "    while vcap.isOpened():\n",
    "        # Read a frame\n",
    "        ret, frame = vcap.read()\n",
    "        if not ret or frame_count == frames_to_process:\n",
    "            break\n",
    "\n",
    "        # Apply the body classifier\n",
    "        bodies = detector.process(frame)\n",
    "        \n",
    "        # Draw the bounding boxes for any bodies identified\n",
    "        # and add detected bounding box to output data\n",
    "        id_count = 0\n",
    "        for (left, bottom, w, h) in bodies:\n",
    "            right, top = left + w, bottom + h\n",
    "            cv2.rectangle(frame, (left, bottom), (right, top), green, 2)\n",
    "            index = frame_count+id_count\n",
    "            output_data += [[index, frame_count, id_count, left, bottom, right, top]]\n",
    "            id_count += 1\n",
    "        \n",
    "        # Get the ground-truth\n",
    "        bodies_gt = df_gt.loc[(slice(None), frame_count, slice(None)), :].to_numpy().astype(int)\n",
    "\n",
    "        # Draw the bounding boxes for ground-truth\n",
    "        for (left, top, right, bottom) in bodies_gt:\n",
    "            cv2.rectangle(frame, (left, bottom), (right, top), red, 1)\n",
    "\n",
    "        # Compute and put FPS on frame\n",
    "        fps = cv2.getTickFrequency() / (fps_timer[1] - fps_timer[0]);\n",
    "        fps_timer[0] = fps_timer[1]\n",
    "        fps_timer[1] = cv2.getTickCount()\n",
    "        cv2.putText(frame,\n",
    "            text=f\"FPS: {int(fps)}\",\n",
    "            org=(frame_width -60, frame_height -5),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=0.3,\n",
    "            color=green,\n",
    "            thickness=1\n",
    "        );\n",
    "\n",
    "        # Save frame\n",
    "        processed_frames[frame_count] = frame\n",
    "        frame_count += 1\n",
    "\n",
    "        # Show in app\n",
    "        cv2.imshow(window_name, frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    # end timer\n",
    "    end = time.time()\n",
    "    overall_elapsed_time = end - start\n",
    "    elapsed_time_per_frame = overall_elapsed_time / frame_count\n",
    "\n",
    "    print(\"Done!\")\n",
    "    print(f\"{frame_count} frames processed in {overall_elapsed_time} seconds.\")\n",
    "    print(f\"({elapsed_time_per_frame}) seconds per frame.\")\n",
    "    print(f\"({1/elapsed_time_per_frame}) frames per second.\")\n",
    "\n",
    "    # Write processed frames to file\n",
    "    for frame in processed_frames:\n",
    "        vout.write(frame)\n",
    "\n",
    "#     print(f\"Output saved to \\\"{output_filename}\\\".\")\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    df_out = pd.DataFrame(output_data, columns=['Index', 'Frame', 'Id', 'Left', 'Bottom', 'Right', 'Top'])\n",
    "#     df_out['Index'] = df_out.index\n",
    "    df_out.set_index(['Index', 'Frame', 'Id'], inplace=True)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-hybrid",
   "metadata": {},
   "source": [
    "# Functions to compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "waiting-flashing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T12:53:23.744619Z",
     "start_time": "2021-03-24T12:53:23.516772Z"
    },
    "code_folding": [
     4,
     5,
     12,
     13,
     37,
     40,
     45,
     53,
     66,
     84
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 3.],\n",
       "       [1., 3.],\n",
       "       [2., 3.],\n",
       "       [3., 3.],\n",
       "       [4., 3.],\n",
       "       [5., 3.],\n",
       "       [6., 3.],\n",
       "       [7., 3.],\n",
       "       [8., 3.],\n",
       "       [9., 3.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import factorial\n",
    "import multiprocessing\n",
    "import itertools\n",
    "\n",
    "def compute_bb_area(bb):\n",
    "    \"\"\" bb: [left, bottom, right, top] \n",
    "        return: bounding box area \"\"\"\n",
    "    left, bottom, right, top = 0, 1, 2, 3\n",
    "    width = bb[right] - bb[left]\n",
    "    height = bb[bottom] - bb[top]\n",
    "    return abs(width * height)\n",
    "\n",
    "def compute_iou(bb1, bb2):\n",
    "    \"\"\" bb1 and bb2: [left, bottom, right, top]\n",
    "        return: intersection over area (iou) \n",
    "        reference: http://jsfiddle.net/Lqh3mjr5/ \"\"\"   \n",
    "    left, bottom, right, top = 0, 1, 2, 3\n",
    "    \n",
    "    # Intersection Bouding Box\n",
    "    bbi = [max(bb1[left], bb2[left]),      # left\n",
    "           max(bb1[bottom], bb2[bottom]),  # bottom\n",
    "           min(bb1[right], bb2[right]),    # right\n",
    "           min(bb1[top], bb2[top])]        # top\n",
    "    \n",
    "    # Compute the bounding boxes areas\n",
    "    bbi_area = compute_bb_area(bbi)\n",
    "    bb1_area = compute_bb_area(bb1)\n",
    "    bb2_area = compute_bb_area(bb2)\n",
    "    bbu_area = bb1_area + bb2_area - bbi_area\n",
    "    \n",
    "    iou = bbi_area / bbu_area\n",
    "    \n",
    "#     print('\\t', bb1, bb2, bbi, bb1_area, bb2_area, bbi_area, bbu_area, iou)\n",
    "    \n",
    "    # Return the intersection area over union area\n",
    "    return iou\n",
    "\n",
    "def compute_permutation_size(n, r):\n",
    "    return int(factorial(n) / factorial(n -r))\n",
    "\n",
    "def chunker(iterator, size):\n",
    "    iterator = iter(iterator)\n",
    "    while chunk := list(itertools.islice(iterator, size)):\n",
    "        yield chunk\n",
    "\n",
    "def parallel_process(f, data):\n",
    "    global cpu_threads\n",
    "    pool = multiprocessing.Pool(cpu_threads)\n",
    "    for result in pool.imap_unordered(f, data):\n",
    "        yield result\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "def func_chunk(chunk):\n",
    "    global A, B, lenA, lenB\n",
    "    \n",
    "    local_costs = []\n",
    "    for combs in chunk:\n",
    "        for a, b in zip(A[list(combs)], B):\n",
    "            local_costs += [compute_iou(a, b)]\n",
    "    \n",
    "    local_costs = np.array(local_costs).reshape((-1, lenB))\n",
    "    total_cost = local_costs.sum(axis=1)\n",
    "    index = total_cost.argmax()\n",
    "    return chunk[index], total_cost[index]\n",
    "    \n",
    "def optimize():\n",
    "    global permutations, chunksize, A, B, lenA, lenB\n",
    "    \n",
    "    results = {'costs': [], 'combs': []}\n",
    "    \n",
    "    chunks = chunker(permutations, chunksize)\n",
    "    for result in parallel_process(func_chunk, chunks):\n",
    "        comb, cost = result\n",
    "        results['costs'] += [cost]\n",
    "        results['combs'] += [comb]\n",
    "\n",
    "    if len(results['costs']) > 0:\n",
    "        index = results['costs'].index(max(results['costs']))\n",
    "        results['costs'] = results['costs'][index]\n",
    "        results['combs'] = results['combs'][index]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def check_frame_in_df(frame, df):\n",
    "    for v in df.index.values:\n",
    "        if v[1] == frame:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def compute_accuracy(df_gt, df_out, frames_to_process=100, verbose=False):\n",
    "    global permutations, chunksize, cpu_threads, total_threads, A, B, lenA, lenB\n",
    "    \n",
    "    accuracy_values = []\n",
    "    for frame in range(frames_to_process):\n",
    "        if verbose: print('frame:', frame)\n",
    "\n",
    "        n_bboxes = df_gt.loc[(slice(None), frame, slice(None)), :].index.size\n",
    "        if verbose: print('ground-truth ids:', n_bboxes)\n",
    "\n",
    "        # Skip current frame if there is no data for it\n",
    "        if not check_frame_in_df(frame, df_gt) or not check_frame_in_df(frame, df_out):\n",
    "            accuracy_values += [[frame, 0]]\n",
    "            if verbose: print(f'warning: frame {frame} was skipped.')\n",
    "            continue\n",
    "        # A, B / lenA needs to be greater than lenB.\n",
    "        A = df_gt.loc[(slice(None), frame, slice(None)), :].to_numpy()\n",
    "        B = df_out.loc[(slice(None), frame, slice(None)), :].to_numpy()\n",
    "        lenA, lenB = len(A), len(B)\n",
    "        if (lenB > lenA):\n",
    "            A, B = B, A\n",
    "            lenA, lenB = lenB, lenA\n",
    "        if verbose: print('len A:', lenA, 'len B:', lenB)\n",
    "\n",
    "        maximum_allowed_permutation_size = 3628800  # for sake of my ram\n",
    "        permutations_size = compute_permutation_size(lenA, lenB)\n",
    "        if verbose: print(\"Permutations size:\", permutations_size)\n",
    "        if (permutations_size <= maximum_allowed_permutation_size):\n",
    "            cpu_threads = min(permutations_size, multiprocessing.cpu_count())\n",
    "            if verbose: print(\"CPU Threads:\", cpu_threads)\n",
    "\n",
    "            chunksize = max(1, permutations_size // cpu_threads)\n",
    "            if verbose: print(\"Chunk size:\", chunksize)\n",
    "\n",
    "            total_threads = max(cpu_threads, chunksize // cpu_threads)\n",
    "            if verbose: print(\"Total Threads:\", total_threads)\n",
    "\n",
    "            elapsed_time = -time.time()\n",
    "            permutations = itertools.permutations(range(lenA), lenB)\n",
    "            results = optimize()\n",
    "            elapsed_time += time.time()\n",
    "\n",
    "            if verbose: print(\"Elapsed Time:\", elapsed_time, 's')\n",
    "            if verbose: print(\"Results:\\n\", results)\n",
    "                \n",
    "            accuracy_values += [[frame, results['costs']]]\n",
    "        else:\n",
    "            if verbose: print(\"Ignoring: permutation size greater than allowed.\")\n",
    "            pass\n",
    "        if verbose: print('-' * 80)\n",
    "    \n",
    "    accuracy_values = np.array(accuracy_values)\n",
    "    if len(accuracy_values) == 0:\n",
    "        return np.array([0, 0])\n",
    "#     total_average_accuracy = accuracy_values[:,1].sum() / frames_to_process\n",
    "    return accuracy_values\n",
    "\n",
    "\n",
    "########################################################### testing\n",
    "width, height = 845, 480\n",
    "left, bottom = 600, 300\n",
    "right, top = left + width, bottom + height\n",
    "df_gt = setup_ground_truth('TownCentre-groundtruth.top', crop_window=(left, bottom, right, top), resize='360p')\n",
    "df_out = df_gt.copy()\n",
    "\n",
    "compute_accuracy(df_gt, df_out, frames_to_process=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-silence",
   "metadata": {},
   "source": [
    "# Comparing each detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "addressed-stupid",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T13:15:07.467420Z",
     "start_time": "2021-03-24T13:14:28.265924Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haar Cascade\n",
      "Frame width: 640\n",
      "Frame width: 360\n",
      "Video fps: 25.0\n",
      "Done!\n",
      "600 frames processed in 11.248070478439331 seconds.\n",
      "(0.01874678413073222) seconds per frame.\n",
      "(53.34248226396692) frames per second.\n",
      "Average: 0.058364201292905676\n",
      "Median: 0.0\n",
      "Std: 0.18229374830167264\n",
      "Var: 0.03323101066987357\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Backgroun Subtraction\n",
      "Frame width: 640\n",
      "Frame width: 360\n",
      "Video fps: 25.0\n",
      "Done!\n",
      "600 frames processed in 4.84501838684082 seconds.\n",
      "(0.0080750306447347) seconds per frame.\n",
      "(123.83853931898662) frames per second.\n",
      "Average: 3.316601076548535\n",
      "Median: 1.0156270233652454\n",
      "Std: 5.716630367658067\n",
      "Var: 32.6798627604304\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "YOLOv4\n",
      "Frame width: 640\n",
      "Frame width: 360\n",
      "Video fps: 25.0\n",
      "80 classes loaded: []\n",
      "Done!\n",
      "600 frames processed in 10.357662439346313 seconds.\n",
      "(0.017262770732243856) seconds per frame.\n",
      "(57.92812842796862) frames per second.\n",
      "Average: 4.988377856267438\n",
      "Median: 1.1405778922596603\n",
      "Std: 18.638131511070767\n",
      "Var: 347.3799462239691\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# Get the groud-truth data\n",
    "width, height = 845, 480\n",
    "left, bottom = 600, 300\n",
    "right, top = left + width, bottom + height\n",
    "df_gt = setup_ground_truth('TownCentre-groundtruth.top', crop_window=(left, bottom, right, top), resize='360p')\n",
    "\n",
    "detectors = [\n",
    "    {\n",
    "        'Name': 'Haar Cascade',\n",
    "        'Class': haar_detector,\n",
    "    },\n",
    "    {\n",
    "        'Name': 'Backgroun Subtraction',\n",
    "        'Class': background_subtraction_detector,\n",
    "    },\n",
    "    {\n",
    "        'Name': 'YOLOv4',\n",
    "        'Class': yolo_detector,\n",
    "    },\n",
    "]\n",
    "frames_to_process = 600\n",
    "\n",
    "for i in range(len(detectors)):\n",
    "    print(detectors[i]['Name'])\n",
    "    # Setup the input video\n",
    "    vcap, frame_width, frame_height, fps, n_frames = setup_input('./360p_TownCentreXVID.mp4')\n",
    "\n",
    "    # Setup the output video\n",
    "    vout = setup_output('./output.mp4', frame_width, frame_height, fps)\n",
    "\n",
    "    # Process the detector and save the output file\n",
    "    df_out = process_frames(vcap, vout, df_gt, detector=detectors[i]['Class'](), frames_to_process=frames_to_process)\n",
    "\n",
    "    # # Release\n",
    "    vcap.release()\n",
    "    vout.release()\n",
    "\n",
    "    detector_accuracy = compute_accuracy(df_gt, df_out)\n",
    "    detectors[i]['Accuracy Average'] = np.average(detector_accuracy[:,1])\n",
    "    detectors[i]['Accuracy Median'] = np.median(detector_accuracy[:,1])\n",
    "    detectors[i]['Accuracy Std'] = np.std(detector_accuracy[:,1])\n",
    "    detectors[i]['Accuracy Var'] = np.var(detector_accuracy[:,1])\n",
    "    \n",
    "    print('Average:', detectors[i]['Accuracy Average'])\n",
    "    print('Median:', detectors[i]['Accuracy Median'])\n",
    "    print('Std:', detectors[i]['Accuracy Std'])\n",
    "    print('Var:', detectors[i]['Accuracy Var'])\n",
    "    \n",
    "    print('\\n' + '-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "mediterranean-platinum",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T18:40:33.559959Z",
     "start_time": "2021-03-24T18:40:33.429968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(detectors)\n",
    "df.plot(kind = \"barh\", x=\"Name\", y=\"Accuracy Average\", legend=False,\n",
    "            title=\"Accuracy\", xerr=\"Accuracy Std\", figsize=(15,10));"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
